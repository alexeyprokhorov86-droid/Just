"""
RAG Agent –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É.
–í–∫–ª—é—á–∞–µ—Ç SQL-–ø–æ–∏—Å–∫ –∏ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π) –ø–æ–∏—Å–∫.
"""

import os
from dotenv import load_dotenv
load_dotenv('/home/admin/telegram_logger_bot/.env')

import json
import logging
import requests
import psycopg2
from psycopg2 import sql
import re

logger = logging.getLogger(__name__)

DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PORT = os.getenv("DB_PORT", "5432")
DB_NAME = os.getenv("DB_NAME", "knowledge_base")
DB_USER = os.getenv("DB_USER", "knowledge")
DB_PASSWORD = os.getenv("DB_PASSWORD")
ROUTERAI_API_KEY = os.getenv("ROUTERAI_API_KEY")
ROUTERAI_BASE_URL = os.getenv("ROUTERAI_BASE_URL", "https://routerai.ru/api/v1")

# –ò–º–ø–æ—Ä—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
try:
    from embedding_service import vector_search, index_telegram_message
    VECTOR_SEARCH_ENABLED = True
    logger.info("–í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –≤–∫–ª—é—á–µ–Ω")
except ImportError:
    VECTOR_SEARCH_ENABLED = False
    logger.warning("embedding_service –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –æ—Ç–∫–ª—é—á–µ–Ω")


def get_db_connection():
    return psycopg2.connect(host=DB_HOST, port=DB_PORT, dbname=DB_NAME, user=DB_USER, password=DB_PASSWORD)


def clean_keywords(query: str) -> list:
    """–û—á–∏—â–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –æ—Ç –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏."""
    # –£–±–∏—Ä–∞–µ–º –∑–∞–ø—è—Ç—ã–µ, —Ç–æ—á–∫–∏ –∏ –¥—Ä—É–≥—É—é –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é
    clean_query = re.sub(r'[,.:;!?()"\']', ' ', query)
    keywords = [w.strip() for w in clean_query.split() if len(w.strip()) > 2]
    return keywords if keywords else [query]


def search_telegram_chats_sql(query: str, limit: int = 10) -> list:
    """SQL-–ø–æ–∏—Å–∫ –ø–æ —á–∞—Ç–∞–º (—Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤)."""
    results = []
    conn = get_db_connection()
    keywords = clean_keywords(query)
    try:
        with conn.cursor() as cur:
            cur.execute("""SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name LIKE 'tg_chat_%' AND table_name != 'tg_chats_metadata' AND table_name != 'tg_user_roles'""")
            chat_tables = [row[0] for row in cur.fetchall()]
            for table_name in chat_tables:
                for keyword in keywords[:2]:
                    try:
                        cur.execute(sql.SQL("SELECT timestamp, first_name, message_text, media_analysis, message_type FROM {} WHERE message_text ILIKE %s OR media_analysis ILIKE %s ORDER BY timestamp DESC LIMIT %s").format(sql.Identifier(table_name)), (f"%{keyword}%", f"%{keyword}%", limit))
                        for row in cur.fetchall():
                            chat_name = table_name.replace('tg_chat_', '').split('_', 1)[-1].replace('_', ' ').title()
                            content = row[2] or ""
                            if row[3]:
                                content += f"\n[–ê–Ω–∞–ª–∏–∑]: {row[3][:500]}"
                            result = {"source": f"–ß–∞—Ç: {chat_name}", "date": row[0].strftime("%d.%m.%Y %H:%M") if row[0] else "", "author": row[1] or "", "content": content[:1000], "type": row[4] or "text"}
                            if result not in results:
                                results.append(result)
                    except:
                        continue
    finally:
        conn.close()
    return results[:limit]


def search_telegram_chats_vector(query: str, limit: int = 10) -> list:
    """–í–µ–∫—Ç–æ—Ä–Ω—ã–π (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π) –ø–æ–∏—Å–∫ –ø–æ —á–∞—Ç–∞–º."""
    if not VECTOR_SEARCH_ENABLED:
        return []
    
    try:
        vector_results = vector_search(query, limit=limit, source_type='telegram')
        results = []
        for r in vector_results:
            chat_name = r['source_table'].replace('tg_chat_', '').split('_', 1)[-1].replace('_', ' ').title()
            results.append({
                "source": f"–ß–∞—Ç: {chat_name}",
                "content": r['content'][:1000],
                "type": "text",
                "similarity": r['similarity'],
                "search_type": "vector"
            })
        logger.info(f"–í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return results
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
        return []


def search_telegram_chats(query: str, limit: int = 10) -> list:
    """–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —á–∞—Ç–∞–º."""
    results = []
    seen_contents = set()
    
    vector_results = search_telegram_chats_vector(query, limit=limit)
    for r in vector_results:
        content_key = r['content'][:100]
        if content_key not in seen_contents:
            seen_contents.add(content_key)
            results.append(r)
    
    if len(results) < limit:
        sql_results = search_telegram_chats_sql(query, limit=limit - len(results))
        for r in sql_results:
            content_key = r['content'][:100]
            if content_key not in seen_contents:
                seen_contents.add(content_key)
                r['search_type'] = 'sql'
                results.append(r)
    
    logger.info(f"–ü–æ–∏—Å–∫ –≤ —á–∞—Ç–∞—Ö: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (vector + sql)")
    return results[:limit]


def search_1c_data(query: str, limit: int = 10) -> list:
    """SQL-–ø–æ–∏—Å–∫ –ø–æ –¥–∞–Ω–Ω—ã–º 1–° (—Ü–µ–Ω—ã, –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞, –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç—ã)."""
    prices = []
    nomenclature = []
    contractors = []
    
    conn = get_db_connection()
    keywords = clean_keywords(query)
    
    try:
        with conn.cursor() as cur:
            # 1. –ó–ê–ö–£–ü–û–ß–ù–´–ï –¶–ï–ù–´ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç!)
            for keyword in keywords[:3]:
                try:
                    cur.execute("""
                        SELECT doc_date, doc_number, contractor_name, nomenclature_name, quantity, price, sum_total 
                        FROM purchase_prices 
                        WHERE nomenclature_name ILIKE %s OR contractor_name ILIKE %s 
                        ORDER BY doc_date DESC LIMIT %s
                    """, (f"%{keyword}%", f"%{keyword}%", limit))
                    for row in cur.fetchall():
                        result = {
                            "source": "1–°: –ó–ê–ö–£–ü–û–ß–ù–´–ï –¶–ï–ù–´", 
                            "date": row[0].strftime("%d.%m.%Y") if row[0] else "", 
                            "content": f"{row[3]} –æ—Ç {row[2]}: {row[5]} —Ä—É–±./–µ–¥., –∫–æ–ª-–≤–æ: {row[4]}, —Å—É–º–º–∞: {row[6]} —Ä—É–±. (–¥–æ–∫. {row[1]})", 
                            "type": "price"
                        }
                        if result not in prices:
                            prices.append(result)
                except Exception as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –∑–∞–∫—É–ø–æ—á–Ω—ã—Ö —Ü–µ–Ω: {e}")
            
            # 2. –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞ (—Å–ø—Ä–∞–≤–æ—á–Ω–æ)
            for keyword in keywords[:3]:
                try:
                    cur.execute("SELECT name, code, unit FROM nomenclature WHERE name ILIKE %s OR code ILIKE %s LIMIT %s", (f"%{keyword}%", f"%{keyword}%", limit))
                    for row in cur.fetchall():
                        result = {"source": "1–°: –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞", "content": f"{row[0]} (–∫–æ–¥: {row[1]}, –µ–¥.: {row[2]})", "type": "nomenclature"}
                        if result not in nomenclature:
                            nomenclature.append(result)
                except:
                    pass
            
            # 3. –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç—ã (—Å–ø—Ä–∞–≤–æ—á–Ω–æ)
            for keyword in keywords[:3]:
                try:
                    cur.execute("SELECT name, inn, full_name FROM contractors WHERE name ILIKE %s OR inn ILIKE %s LIMIT %s", (f"%{keyword}%", f"%{keyword}%", limit))
                    for row in cur.fetchall():
                        result = {"source": "1–°: –ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç—ã", "content": f"{row[0]} (–ò–ù–ù: {row[1]})", "type": "contractor"}
                        if result not in contractors:
                            contractors.append(result)
                except:
                    pass
    finally:
        conn.close()
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: —Å–Ω–∞—á–∞–ª–∞ —Ü–µ–Ω—ã, –ø–æ—Ç–æ–º –æ—Å—Ç–∞–ª—å–Ω–æ–µ
    results = prices[:limit]
    remaining = limit - len(results)
    if remaining > 0:
        results.extend(nomenclature[:remaining])
        remaining = limit - len(results)
    if remaining > 0:
        results.extend(contractors[:remaining])
    
    logger.info(f"–ü–æ–∏—Å–∫ 1–° –ø–æ {keywords}: —Ü–µ–Ω—ã={len(prices)}, –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞={len(nomenclature)}, –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç—ã={len(contractors)}")
    return results[:limit]


def search_internet(query: str) -> tuple:
    """–ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ —á–µ—Ä–µ–∑ Perplexity. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (—Ç–µ–∫—Å—Ç, —Å–ø–∏—Å–æ–∫_—Å—Å—ã–ª–æ–∫)."""
    if not ROUTERAI_API_KEY:
        return "", []
    try:
        response = requests.post(
            f"{ROUTERAI_BASE_URL}/chat/completions",
            headers={"Authorization": f"Bearer {ROUTERAI_API_KEY}", "Content-Type": "application/json"},
            json={"model": "perplexity/sonar", "messages": [{"role": "user", "content": query}]},
            timeout=60
        )
        result = response.json()
        
        if "choices" not in result:
            return "", []
        
        text = result["choices"][0]["message"]["content"]
        citations = result.get("citations", [])
        
        return text, citations
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç: {e}")
        return "", []


def generate_response(question: str, db_results: list, web_results: str, web_citations: list = None, chat_context: str = "") -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
    if not ROUTERAI_API_KEY:
        return "API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"
    try:
        context_parts = []
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ç–∏–ø—É
        prices = [r for r in db_results if r.get('type') == 'price']
        other_1c = [r for r in db_results if r.get('source', '').startswith('1–°') and r.get('type') != 'price']
        chats = [r for r in db_results if r.get('source', '').startswith('–ß–∞—Ç')]
        
        # –°–Ω–∞—á–∞–ª–∞ –∑–∞–∫—É–ø–æ—á–Ω—ã–µ —Ü–µ–Ω—ã (–ü–†–ò–û–†–ò–¢–ï–¢!)
        if prices:
            context_parts.append("=== –ó–ê–ö–£–ü–û–ß–ù–´–ï –¶–ï–ù–´ –ö–û–ú–ü–ê–ù–ò–ò (–¥–∞–Ω–Ω—ã–µ 1–°) ===")
            for i, res in enumerate(prices, 1):
                context_parts.append(f"{i}. {res.get('date', '')} {res['content']}")
        
        # –ü–æ—Ç–æ–º —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏ 1–°
        if other_1c:
            context_parts.append("\n=== –°–ü–†–ê–í–û–ß–ù–ò–ö–ò 1–° ===")
            for i, res in enumerate(other_1c, 1):
                context_parts.append(f"{i}. [{res['source']}] {res['content'][:300]}")
        
        # –ü–æ—Ç–æ–º —á–∞—Ç—ã
        if chats:
            context_parts.append("\n=== –ò–ó –ß–ê–¢–û–í ===")
            for i, res in enumerate(chats[:5], 1):
                similarity_info = f" [—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {res['similarity']:.0%}]" if 'similarity' in res else ""
                context_parts.append(f"{i}.{similarity_info} {res['content'][:300]}")
        
        # –ò–Ω—Ç–µ—Ä–Ω–µ—Ç
        if web_results:
            context_parts.append("\n=== –ò–ù–¢–ï–†–ù–ï–¢ ===")
            context_parts.append(web_results[:2000])
        
        context = "\n".join(context_parts)
        
        prompt = f"""–¢—ã ‚Äî RAG-–∞–≥–µ–Ω—Ç –∫–æ–º–ø–∞–Ω–∏–∏. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º.

–í–û–ü–†–û–°: {question}

–ù–ê–ô–î–ï–ù–ù–´–ï –î–ê–ù–ù–´–ï:
{context if context else "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."}

–í–ê–ñ–ù–´–ï –ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –ó–ê–ö–£–ü–û–ß–ù–´–ï –¶–ï–ù–´ –ö–û–ú–ü–ê–ù–ò–ò ‚Äî —ç—Ç–æ –†–ï–ê–õ–¨–ù–´–ï —Ü–µ–Ω—ã –ø–æ –∫–æ—Ç–æ—Ä—ã–º –º—ã –ø–æ–∫—É–ø–∞–µ–º —Ç–æ–≤–∞—Ä. –û–Ω–∏ –≤ —Ä–∞–∑–¥–µ–ª–µ "–ó–ê–ö–£–ü–û–ß–ù–´–ï –¶–ï–ù–´ –ö–û–ú–ü–ê–ù–ò–ò". –í–°–ï–ì–î–ê —É–∫–∞–∑—ã–≤–∞–π –∏—Ö –≤ –æ—Ç–≤–µ—Ç–µ!
2. –ï—Å–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –æ —Ü–µ–Ω–µ "—É –Ω–∞—Å" ‚Äî —ç—Ç–æ –∑–∞–∫—É–ø–æ—á–Ω—ã–µ —Ü–µ–Ω—ã –∏–∑ 1–°
3. –ï—Å–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –æ —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ü–µ–Ω–∞—Ö ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –¥–∞–Ω–Ω—ã–µ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞
4. –£–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã: —Ü–µ–Ω—É, –¥–∞—Ç—É, –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞
5. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –¥–∞–Ω–Ω—ã–µ

–û—Ç–≤–µ—Ç:"""

        response = requests.post(f"{ROUTERAI_BASE_URL}/chat/completions", headers={"Authorization": f"Bearer {ROUTERAI_API_KEY}", "Content-Type": "application/json"}, json={"model": "google/gemini-3-flash-preview", "messages": [{"role": "user", "content": prompt}], "max_tokens": 2000}, timeout=60)
        result = response.json()
        if "choices" in result:
            response_text = result["choices"][0]["message"]["content"]
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –≤ –∫–æ–Ω–µ—Ü –µ—Å–ª–∏ –µ—Å—Ç—å
            if web_citations:
                response_text += "\n\nüìé **–ò—Å—Ç–æ—á–Ω–∏–∫–∏:**"
                for i, url in enumerate(web_citations[:5], 1):
                    response_text += f"\n{i}. {url}"
            
            return response_text
        return "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
    except Exception as e:
        return f"–û—à–∏–±–∫–∞: {e}"


def classify_question(question: str) -> dict:
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–æ–∏—Å–∫–∞."""
    if not ROUTERAI_API_KEY:
        return {"search_1c": True, "search_chats": True, "search_web": False, "keywords": question, "priority": "1c"}
    try:
        prompt = f"""–û–ø—Ä–µ–¥–µ–ª–∏ –≥–¥–µ –∏—Å–∫–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
–ò—Å—Ç–æ—á–Ω–∏–∫–∏: 1–° (—Ü–µ–Ω—ã, –∑–∞–∫—É–ø–∫–∏, —Ç–æ–≤–∞—Ä—ã), –ß–∞—Ç—ã (–æ–±—Å—É–∂–¥–µ–Ω–∏—è), –ò–Ω—Ç–µ—Ä–Ω–µ—Ç (–≤–Ω–µ—à–Ω–µ–µ).
–ò–∑–≤–ª–µ–∫–∏ 1-3 –ö–õ–Æ–ß–ï–í–´–• –°–õ–û–í–ê (—Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –±–µ–∑ –∑–∞–ø—è—Ç—ã—Ö: —Å–∞—Ö–∞—Ä –º—É–∫–∞ —Ç–æ—Ä—Ç)

–í–æ–ø—Ä–æ—Å: {question}

JSON: {{"search_1c": true/false, "search_chats": true/false, "search_web": true/false, "keywords": "—Å–ª–æ–≤–æ1 —Å–ª–æ–≤–æ2", "priority": "1c/chats/web"}}"""
        response = requests.post(f"{ROUTERAI_BASE_URL}/chat/completions", headers={"Authorization": f"Bearer {ROUTERAI_API_KEY}", "Content-Type": "application/json"}, json={"model": "google/gemini-3-flash-preview", "messages": [{"role": "user", "content": prompt}], "max_tokens": 200}, timeout=30)
        result = response.json()
        if "choices" in result:
            import re
            match = re.search(r'\{[^}]+\}', result["choices"][0]["message"]["content"])
            if match:
                return json.loads(match.group())
        return {"search_1c": True, "search_chats": True, "search_web": False, "keywords": question, "priority": "1c"}
    except:
        return {"search_1c": True, "search_chats": True, "search_web": False, "keywords": question, "priority": "1c"}


async def process_rag_query(question: str, chat_context: str = "") -> str:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ RAG-–∑–∞–ø—Ä–æ—Å–∞."""
    logger.info(f"RAG –∑–∞–ø—Ä–æ—Å: {question}")
    classification = classify_question(question)
    logger.info(f"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: {classification}")
    keywords = classification.get("keywords", question)
    db_results = []
    
    # –ü–æ–∏—Å–∫ –≤ 1–° (SQL) ‚Äî –≤—Å–µ–≥–¥–∞ –ø–µ—Ä–≤—ã–º
    if classification.get("search_1c", True):
        c1_results = search_1c_data(keywords, limit=15)
        db_results.extend(c1_results)
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ –≤ 1–°: {len(c1_results)}")
    
    # –ü–æ–∏—Å–∫ –≤ —á–∞—Ç–∞—Ö (–≤–µ–∫—Ç–æ—Ä–Ω—ã–π + SQL)
    if classification.get("search_chats", True):
        chat_results = search_telegram_chats(keywords, limit=10)
        db_results.extend(chat_results)
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ –≤ —á–∞—Ç–∞—Ö: {len(chat_results)}")
    
    logger.info(f"–í—Å–µ–≥–æ –≤ –ë–î: {len(db_results)}")
    
    # –ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
    web_results = ""
    web_citations = []
    if classification.get("search_web", False):
        web_results, web_citations = search_internet(question)
    
    return generate_response(question, db_results, web_results, web_citations, chat_context)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ bot.py)
async def index_new_message(table_name: str, message_id: int, content: str):
    """–ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞."""
    if not VECTOR_SEARCH_ENABLED:
        return
    
    if not content or len(content.strip()) < 10:
        return
    
    try:
        index_telegram_message(table_name, message_id, content)
        logger.debug(f"–ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ {message_id} –∏–∑ {table_name}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
